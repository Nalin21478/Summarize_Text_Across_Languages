{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from easynmt import EasyNMT\n",
    "import json\n",
    "import torch\n",
    "# Check if GPU is available\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Initialize EasyNMT model on the available device\n",
    "model = EasyNMT('opus-mt', device=device)\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"hungnm/multilingual-amazon-review-sentiment-processed\")\n",
    "desired_features = ['stars', 'text', 'language', 'label']\n",
    "reduced_dataset = dataset.select_columns(desired_features)\n",
    "train= reduced_dataset['validation']\n",
    "\n",
    "# Filter datasets by language\n",
    "de_train=train.filter(lambda example: example['language']=='de')\n",
    "fr_train=train.filter(lambda example: example['language']=='fr')\n",
    "es_train=train.filter(lambda example: example['language']=='es')\n",
    "ja_train=train.filter(lambda example: example['language']=='ja')\n",
    "zh_train=train.filter(lambda example: example['language']=='zh')\n",
    "\n",
    "# Group datasets by language\n",
    "ds={\"de\":de_train,\"fr\":fr_train,\"es\":es_train, \"ja\":ja_train,\"zh\":zh_train}\n",
    "language_dataset={\"de\":[],\"es\":[],\"fr\":[],\"ja\":[],\"zh\":[]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': Dataset({\n",
       "     features: ['stars', 'text', 'language', 'label'],\n",
       "     num_rows: 7848\n",
       " }),\n",
       " 'fr': Dataset({\n",
       "     features: ['stars', 'text', 'language', 'label'],\n",
       "     num_rows: 7929\n",
       " }),\n",
       " 'es': Dataset({\n",
       "     features: ['stars', 'text', 'language', 'label'],\n",
       "     num_rows: 7921\n",
       " }),\n",
       " 'ja': Dataset({\n",
       "     features: ['stars', 'text', 'language', 'label'],\n",
       "     num_rows: 8000\n",
       " }),\n",
       " 'zh': Dataset({\n",
       "     features: ['stars', 'text', 'language', 'label'],\n",
       "     num_rows: 8000\n",
       " })}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 15008/15023.0 [10:20<00:00, 24.18it/s]/home/nalin/yes/envs/torch/lib/python3.11/site-packages/tqdm/std.py:636: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "100%|██████████| 15024/15023.0 [10:21<00:00, 24.19it/s]\n",
      "12272it [10:05, 20.28it/s]                             \n",
      "100%|██████████| 11776/11771.0 [05:50<00:00, 33.56it/s]\n",
      "100%|██████████| 8048/8041.0 [07:28<00:00, 17.93it/s]\n",
      "100%|██████████| 10736/10733.0 [06:24<00:00, 27.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Translate and extend language datasets\n",
    "for language,dset in ds.items():\n",
    "    input_sentences = dset['text']\n",
    "    translated_texts = model.translate(input_sentences, source_lang=language, target_lang='en', show_progress_bar=True)\n",
    "    com_data = Dataset.from_dict({\n",
    "        'text':dset['text'],\n",
    "        'en': translated_texts,\n",
    "        'label': dset['label'],\n",
    "        'stars': dset['stars']\n",
    "    })\n",
    "    language_dataset[language].extend(com_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in language_dataset.items():\n",
    "    file_name=f'{i}_val_en.json'\n",
    "    with open(file_name, \"w\") as file:\n",
    "        json.dump(j, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
